[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About me",
    "section": "",
    "text": "My name is Michał Śmielak. I’m an wildlife biologist, working in the field handling animals and in the office wrangling data. Originally from Poland, over the years I have been involved in projects in Europe, Australia and Africa.\nI am interested in various aspects of animal ecology, including (but not limited to) behavioural ecology of mammals, reptiles and amphibians, conservation, ecosystem management and human-wildlife conflicts.\nI write code (mostly in R) to transform raw data collected in the field into results and conservation outcomes. I also build custom research equipment, often using Arduino and other open-source platforms, usually when there is no off-the-shelf solution to measure something and sometimes just for fun.\nThis website is hopefully going to be a repository of my various projects and a way to share them with fellow researchers.\n\nEducation\n\n2014-\nPhD candidate at the School of Environmental and Rural Sciences\nUniversity of New England in Armidale, Australia.\n\n\n2006-2012\nMSc in environmental protection, Inter-Faculty Studies in Environmental Protection (MSOŚ)\nCentre for the Studies of Envoronment and Sustainability, Unviersity of Warsaw, Poland."
  },
  {
    "objectID": "technology.html",
    "href": "technology.html",
    "title": "Technology",
    "section": "",
    "text": "Various electronic hadware, mostly for use in wildlife research.\n\n\nwilduino\n\n\n\n\n\nwilduino is a project of an animal-borne logger. In its concept, it is a modular, open-source device consisting of a microcontroller board and a range of “shields”, similar to Arduino design, but much smaller and optimised for low power consumption. First prototypes include GPS, 9 DOF IMU and altimeter to track 3D movements of animals. Baseboard (Arduino-based) also has LoRa communication.\nThe wilduino project is currently on hold, but PCB design and rudimentary code is available in a GitHub repository.\nThis project was co-funded by the Holsworth Wildlife Research Endowment."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Extracting date and time from camera trap photos using R and tesseract\n\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMar 29, 2021\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Reproducible code",
    "section": "",
    "text": "Below you will find various examples of reproducible code that I came up with over the years - mostly functions and packages developed in R to help with ecological data analysis. Hopefully, this will be updated over time.\n\n\nmoonlit package\n\n\n\n\n\nmoonlit - R package I’ve been developing since 2018. It is a model to predict moonlight intensity on the ground for any given place and time, based on the position of the moon and a number of correction factors. It provides illumination measures that are much more biologically meaningful than moon phase, particularly useful in behavioural ecology and ALAN (artificial light at night) studies.\nThis package is available from a GitHub repository."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "My name is Michał Śmielak. I'm an wildlife biologist, working in the field handling animals and in the office wrangling data. Originally from Poland, over the years I have been involved in projects in Europe, Australia and Africa.\nI am interested in various aspects of animal ecology, including (but not limited to) behavioural ecology of mammals, reptiles and amphibians, conservation, ecosystem management and human-wildlife conflicts.\nI write code (mostly in R) to transform raw data collected in the field into results and conservation outcomes. I also build custom research equipment, often using Arduino and other open-source platforms, usually when there is no off-the-shelf solution to measure something and sometimes just for fun.\nThis website is hopefully going to be a repository of my various projects and a way to share them with fellow researchers."
  },
  {
    "objectID": "posts/2021-03-29-extracting-date-and-time-from-photo-using-ocr-engine-tesseract/index.html",
    "href": "posts/2021-03-29-extracting-date-and-time-from-photo-using-ocr-engine-tesseract/index.html",
    "title": "Extracting date and time from camera trap photos using R and tesseract",
    "section": "",
    "text": "Background\nRecently I came across an interesting issue. My University runs a field station at a rural property called Newholme where a grid of camera traps was set up a few years back. Cameras are solar-powered and form a mesh network where photos are relayed from one camera to another and finally to the base station located at the station building. Unfortunately, due to a firmware bug, for the first few years, the EXIF data was wiped from each photo as it was relayed so we could only get the date and time when the file was saved on the base station, which could be minutes or days after it was taken. Original metadata was embedded in the picture itself as text, like this:\n\n\n\nsample image\n\n\nThe manufacturer (Buckeye) eventually fixed this issue and after a firmware update photos now have metadata embedded in EXIF fields. However, to use all the data from before the update, we needed to assign date and time to each picture. It was done manually for some small subset but it is a tedious process prone to errors, so I decided to try and automate it.\n\n\nOCR and the tesseract package\nI have used OCR (optical character recognition) software before and I thought there is probably an R package that can read the text and sure enough - a powerful, open-source OCR engine tesseract is availabe in R through a package tesseract.\nWe will need a couple of libraries first:\n\nlibrary(magick)\nlibrary(tesseract)\nlibrary(tidyverse)\nTo help tesseract read our data, we can clip interesting parts from the photo. In this case, I want to read the date and time so we can clip that part of the image. We can use code:\n# import photo\nimage_read(photo1)%&gt;%\n\n# crop date field\nimage_crop(\"68x12+0+468\")\nWhere first two values (68x12) represent the size of the cropped field, and the second two (+0+468) represent the position of the top left corner of that field. As we can see, that gives us desired part of the photo:\n\n\n\ncropped date field\n\n\nTesseract is not dealing well with inverted images so we need to do some more preprocessing before we can run the OCR engine. We will invert the picture, then we will enlarge it 10 times (photo is only 640x480 px and the original digits are only 9 pixels high), increase brightness to get rid of the noise and increase contrast to make it easier to read for our engine. This required a little bit of trial and error to get it right, but here is the result:\n\nimage_read(photo1)%&gt;%\nimage_negate()%&gt;%\nimage_crop(\"68x12+0+468\")%&gt;%\nimage_scale(\"680x120\") %&gt;%\nimage_modulate(brightness = 120)%&gt;%\nimage_contrast(sharpen = 100)\n\n\n\npreprocessed date field\n\n\nThis is already looking better. The narrow strip on the right is there because the actual width of the field changes depending on the number of digits and otherwise would clip the last digit on some long dates. We will deal with it later.\nNow we can run the OCR engine and see what we get.\n\n#import and preprocess the image\ndate &lt;- image_read(photo1)%&gt;%\nimage_negate()%&gt;%\nimage_crop(\"68x12+0+468\")%&gt;%\nimage_scale(\"680x120\") %&gt;%\nimage_modulate(brightness = 120)%&gt;%\nimage_contrast(sharpen = 100)\n\n#read the text\nocr(date)\nWhich gives us &gt;“3/13/2415 |”\nAs you can see, tesseract wrongly identified 0 as 4. For other photos, the results varied from correct or almost correct to a random sequence of letters and digits that didn’t make any sense. The “pixelated” font that the camera is using is making it hard for the engine to read some digits correctly. We need to dig deeper and make use of the tesseract training mechanism.\nTo do that we can prepare a training set consisting of our preprocessed crops, load them into a program, generate a box for each digit and then assign it a correct value. We can generate our training dataset using a simple loop to crop date and time fields from each photo, preprocess it and save each one as a new file:\n\n#create a list of training files\nfiles &lt;- list.files(path=\"./Datasets/02a\", full.names=TRUE)\n\n#using the list of images \nfor (row in 1:NROW(files)) {\n  \n  #display iteration to see progress\n  print(row)\n  \n  # read the i-th image and invert it\n  pic &lt;- image_negate(image_read(files[row]))\n  \n  # extract parts of the image to read\n\n  \n  date &lt;- image_crop(pic, \"68x12+0+468\")%&gt;%\n    image_scale(\"680x120\") %&gt;%\n    image_modulate(brightness = 140)%&gt;%\n    image_contrast(sharpen = 100)%&gt;%\n    image_median(radius = 5)%&gt;%\n    \n    \n   time &lt;- image_crop(pic, \"50x12+296+468\")%&gt;%\n    image_scale(\"500x120\") %&gt;%\n    image_modulate(brightness = 140)%&gt;%\n    image_contrast(sharpen = 100)%&gt;%\n    image_median(radius = 5)%&gt;%\n    image_quantize(max=2)\n  \n\n  \n #write output for training\n  \n  newfile &lt;- file.path(paste0(\"./Datasets/Training/date_\", row, \".jpg\"))\n  \n  image_write(date, newfile, quality=100)\n  \n  newfile &lt;- file.path(paste0(\"./Datasets/Training/time_\", row, \".jpg\"))\n  \n  image_write(time, newfile, quality=100)\n  \n}\nNow we can move to software for tesseract training (it can be done from the terminal as well, but since I had no prior experience with tesseract, I found this software to be easier to use). We need to download jTessBoxEditor and follow the instructions. Combine our training files into a multi-page TIFF (Tools-&gt;Merge TIFF), then we go to the Trainer tab, select our input file (the newly generated TIFF) and select Generate Box File from the drop-down list. It will then generate a box around each digit and assign values, best it can. We can now move to the Box Editor tab, load our newly generated training set and go through the boxes and edit them to fix values that were wrongly assigned:\n\n\n\ntraining boxes\n\n\nI did that for a sample of 142 dates and times (around 2000 characters in total). We then save our training data, go back to the trainer tab and use it for the actual training, selecting functions: Train with existing box, then Shape Clustering and finally Dictionary. This results in a new “language” (in our case simply a font) that can be used as a parameter in the OCR engine.\nSo we need to set up this new engine by assigning a language (I called it “buc”). We can further help tesseract by limiting the symbols it will look for to just digits, “/” and “:”” since there are no other characters in the date and time fields:\n\nnumbers &lt;- tesseract(\"buc\", datapath = \"./Datasets/train\", options = list(tessedit_char_whitelist = \"0123456789:/\"))\n\nocr(test, engine = numbers)\nRunning this on our dataset gives much better results, but for whatever reason, the engine is still struggling with some digits, particularly 6, 8 and 0. Even though these are generated by the camera trap and are identical, the same digit is sometimes read correctly, and sometimes not, with 8 being misread every single time as either 6 or 0. I spent hours trying to tweak the training data and even though it met all the guidelines (more than 20 instances of every digit etc.) I could never get it to work. Not only that, I couldn’t find a good reason for it not working sometimes but then working well on the same digits, just in different order.\nI then decided to see if the camera is using an existing font as jTessBoxEditor has an option to generate training files using a known font and it was recommended in the tesseract manual as the best way to train the data. I took a sample date and uploaded it to online font recognition websites like WhatTheFont! and What Font Is, found some similar looking (but not identical) fonts and tried that, but it didn’t make a huge difference and in some cases made it worse. So finally I came up with an idea to create a custom font that would be as close as possible to the one used by Buckeye and use that for training. I found a very helpful website calligraphr which allows you to create a font from your handwriting. You select the symbols you want to use, then you download an automatically generated template to fill with your handwriting (in my case - paste in preprocessed digits) and upload it back to the website which converts it into a font:\n\n\n\nonline font generator - input\n\n\nYou then get a custom generated font that you can install on your computer (I recommend using “install for all users”, you will also need to restart jTessBoxEditor). You then need to create a text file with a sample text - in my case, it was just 0123456789/: repeated 20 times - and use the TIFF/Box Generator tab to generate a new training file:\n\n\n\nboxes generated with the custom font\n\n\nThen you need to repeat the training process. Do not generate new boxes (boxes with correct characters are generated by TIFF/Box Generator), go straight to training using Train with existing box , Shape Clustering and Dictionary and the result is your new “language” that can be then used as a parameter in the tesseract() function. Great thing is that it takes a couple of minutes and not hours like in the previous method.\nNow, using the custom engine, I was getting 100% accuracy (I checked it on 2000 sample photos and there was not a single error) - finally! We can now move to a final code to run through the dataset, extract dates and time and write them into a .csv file. Our photos are already arranged into folders by camera and species so we can use the file path to easily extract these values afterwards.\nThe last thing to mention is that, like in my first example, there are some narrow strips on some crops that are read as digits. Luckily, they are always separated by a space, so we can add a line to remove that space and everything after it from our read values. We also need to get rid of the new line symbol [] at the end of each record which tesseract adds automatically - we will do with another line of code.\n\n\nFinal code\nThis is what the final code looks like:\n### Extracting metadata from camera trap images\n\n# load required libraries\n\nlibrary(magick)\nlibrary(tesseract)\n\n\n# building a tesseract engine\n# using a pre-trained dataset \"buckeye\" (stored in the folder \"font\")\n\nbuckeye &lt;- tesseract(\"buckeye\", datapath = \"./font\")\n\n\n\n# generate a list of files - only .jpg as another format will cause error\n\nfiles &lt;- list.files(path=\"./Data\", full.names=TRUE, recursive = TRUE, pattern = \"jpg\")\n\n\n\n#loop for extracting date and time\n\n#initialise variables\n\nno &lt;- NA\nt &lt;- NA\nd &lt;- NA\n\n\n#starting from the first file and moving through the list of images \n\nfor (row in 1:NROW(files)) {\n  \n  \n  #display progress\n  \n  message(paste0(\"analysing photo \", row, \" out of \", NROW(files)))\n  \n\n  ### actual OCR routine\n  # read the n-th image and invert it\n  \n  pic &lt;- image_negate(image_read(files[row]))\n  \n  \n  # extract parts of the image to read and preprocess for OCR\n  \n   date &lt;- image_crop(pic, \"68x12+0+468\")%&gt;%\n    image_scale(\"680x120\") %&gt;%\n    image_modulate(brightness = 120)%&gt;%\n    image_contrast(sharpen = 100)\n  \n  time &lt;- image_crop(pic, \"50x12+296+468\")%&gt;%\n    image_scale(\"500x120\") %&gt;%\n    image_modulate(brightness = 120)%&gt;%\n    image_contrast(sharpen = 100)\n  \n \n  \n  #read them and write into n-th row of respective variable\n  \n  no[row] &lt;- row\n  d[row] &lt;- ocr(date, engine = buckeye)\n  t[row] &lt;- ocr(time, engine = buckeye)\n  \n  # move to the next file\n}\n\n# cleaning up the data\n# remove artefacts and page breaks\n\nt &lt;- sub(\" .*\", \"\", t)\nt &lt;- sub(\"[\\n]\", \"\", t)\n\nd &lt;- sub(\" .*\", \"\\n\", d)\nd &lt;- sub(\"[\\n]\", \"\", d)\n\n\n#create a dataframe with the read values\n\noutput &lt;- data.frame(no = no,\n                     filename = files,\n                     date &lt;- d,\n                     time &lt;- t)\n\n#write a .csv file\n\nwrite.csv(output, \"extracted_date_and_time.csv\")\n\nYou can now put all the photos to be tagged into the Data folder and execute the code. Depending on how many photos you have, how large your photos are and how fast your computer is it can take from minutes to hours. I was getting around 200 photos per minute on my 7 years old laptop, while my supervisor was going through more than 1000 photos per minute on his much newer and faster Mac. Still, I recommend running it in smaller chunks, that way in case of an error you are not losing 10h of processing.\nI intentionally didn’t want to do any editing of the existing photos (disk space, maintaining 2 copies etc) and instead decided to save the results as a separate .csv file. In case you want to rename your photos and write this metadata into the picture itself, I recommend you read a very informative post by John Vanek where he details how to manipulate EXIF data. Luckily, he was able to use the default tesseract engine with great success and if your camera has better resolution and uses a more standard font, you might not need to worry about training the engine at all."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "2014-\nThe community ecology of threatened, critical-weightrange, terrestrial mammals in response to wild canid and feral cat control.\nPhD project, part of the Predator-Prey-Plan-People project, Invasive Animals Cooperative Research Centre.\nTrapping and handling animals, using GPS and VHF telemetry to measure spatio-temporal patterns of activity; extensive remote camera monitoring; experiments measuring non-direct effects of predation; using drones to collect hi-resolution habitat data; data analysis and modelling using R and QGIS."
  },
  {
    "objectID": "research.html#ongoing-projects",
    "href": "research.html#ongoing-projects",
    "title": "Research",
    "section": "",
    "text": "2014-\nThe community ecology of threatened, critical-weightrange, terrestrial mammals in response to wild canid and feral cat control.\nPhD project, part of the Predator-Prey-Plan-People project, Invasive Animals Cooperative Research Centre.\nTrapping and handling animals, using GPS and VHF telemetry to measure spatio-temporal patterns of activity; extensive remote camera monitoring; experiments measuring non-direct effects of predation; using drones to collect hi-resolution habitat data; data analysis and modelling using R and QGIS."
  },
  {
    "objectID": "research.html#past-projects",
    "href": "research.html#past-projects",
    "title": "Research",
    "section": "Past projects",
    "text": "Past projects\n06.2013-01.2014\nSurvey of carnivorous mammals in the Augustowska Primeval Forest.\nPart of the Life11 NAT/PL/428 project “Active conservation of Western capercaillie Tetrao urogallus in Lower Silesian Forest and Augustowska Privemal Forest”\nProject leader. Surveying 73300 ha of forests and ecotone habitat in order to estimate densities and activity patterns of large and medium-sized mammalian carnivores to inform best management and conservation practices for reintroduction of capercaillie.\nDesigning and implementing monitoring protocols, supervising teams of 5-10 people, collating and managing data, engaging with stakeholders and land managers, analysing data and preparing maps and final reports.\n2012-2013\nManagement plan for Natura 2000 sites PLB180001 Pogorze Przemyskie and PLB180003 Gory Slonne\nDesigning and conducting herpetological surveys of sites, identifying risk and proposing mitigation strategies for comprehensive species management. Producing a report including GIS data to for a part of the official management plan.\n04-10.2013\nBreeding ecology and conservation of the European pond turtle Emys orbicularis.\nPart of the POIŚ.05.01.00-00228/9 project “Protecting habitats and species in the Natura 2000 sites in Lubelskie voivodeship” Responsible for field data collection and analysis. The project consisted of several modules, including radio-telemetry and geospatial analysis of habitat use, locating nesting sites, collecting biometric data, geospatial data analysis and preparing maps and active conservation measures.\n04-10.2012\nHerpetological and mammal survey of the Vistula Spit.\nResponsible for designing and conducting a detailed and complex survey, consisting of various research methods, such as trapping, tracking and using trail cameras. Using GIS software to provide spatial data on species distribution; presenting the results in form of written report and maps.\n2011-2014\nWildlife research assistant\nSupporting multiple research projects at the Institute of Ecology, Department of Biology, University of Warsaw.\nTaking part in various surveys conducted by Institute crew. Field data collection, trapping and radio-tracking of different species and data processing. From 02.2012 a graduate research assistant in an original research on amphibian hibernation patterns.\n03-06.2011\nConservation of Aquila pomarina in Romania\nInternship in the project: LIFE08 NAT/RO/000501 coordinated by Milvus Group. Târgu Mureş, Romania. Conducting extensive fieldwork (bird observation, habitat mapping), data collection and analysis, GIS data processing, as well as other activities concerning nature conservation in Transylvania.\n03.2010-08.2011\nBreeding avifauna of the small midfield ponds in Mazurian Lakeland\nMSc research at the Institute of Ecology, Department of Biology, University of Warsaw.\nA survey on 25 small midfield ponds in a post-agricultural landscape of Mazurian Lakeland. The study consisted of 2-year census of breeding bird communities combined with detailed habitat mapping. Collected data was used to determine habitat preferences of different bird species and compared with a corresponding data on larger habitat patches, such as lakes and wetlands. Various techniques were used to collect field data; GIS and statistical software were used for data processing."
  },
  {
    "objectID": "research.html#scholarships-and-awards",
    "href": "research.html#scholarships-and-awards",
    "title": "Research",
    "section": "Scholarships and awards",
    "text": "Scholarships and awards\n2014-2018\nEndeavour International Postgraduate Research Scholarship.\nAustralian Government Department of Education, Science and Training\n2016, 2017\nPostgraduate student research grant\nHolsworth Wildlife Research Endowment, Ecological Society of Australia\n03-06.2011\nErasmus+ Grant\nInternship at Milvus Group, Târgu Mureş, Romania"
  },
  {
    "objectID": "research.html#peer-reviewed-papers",
    "href": "research.html#peer-reviewed-papers",
    "title": "Research",
    "section": "Peer-reviewed papers",
    "text": "Peer-reviewed papers\nŚmielak, M.K., Ballard, G., Fleming, P.J.S. et al. Brushtail possum terrestrial activity patterns are driven by climatic conditions, breeding and moonlight intensity. Mamm Res 68, 547–560 (2023). https://doi.org/10.1007/s13364-023-00691-5\nŚmielak, M.K. Biologically meaningful moonlight measures and their application in ecological research. Behav Ecol Sociobiol 77, 21 (2023). https://doi.org/10.1007/s00265-022-03287-2"
  },
  {
    "objectID": "research.html#conference-papers",
    "href": "research.html#conference-papers",
    "title": "Research",
    "section": "Conference papers",
    "text": "Conference papers\nHowling at the moon. Towards biologically meaningful moonlight measures and how to apply them in ecological research.\nBritish Ecological Society 2020 Conference\nIs enemy’s enemy always a friend? Vague implications of wild dog control on a native marsupial herbivore.\n12th International Mammalogical Congress, Perth 2017"
  },
  {
    "objectID": "research.html#other-publications",
    "href": "research.html#other-publications",
    "title": "Research",
    "section": "Other publications",
    "text": "Other publications\nPawlaczyk P., Kucharzyk S., Wolanski P., Zarzecki R., Melke A., Tatoj K., Wasiak P., Smielak M., Michalski R., Kuberski L. 2013: Management plan for the Natura 2000 site Gory Slonne PLH180013 in podkarpakcie voivodeship.\nFundacja Dziedzictwo Przyrodnicze & Klub Przyrodnikow, commisioned by the Regional Directorate for Environmental Protection in Rzeszow\nSmielak, M. 2012: Herpetological and mammalogical survey, in: Environmental survey of the four sections of the Vistula Spit - potential locations of the shipping channel.\nBiuro Ekspertyz Przyrodniczo-Lesnych"
  }
]